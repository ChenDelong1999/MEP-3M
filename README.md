# MEP-3M: A Large-scale Multi-modal E-Commerce Products Dataset

> [Delong Chen](https://chendelong.world/), [Fan Liu](https://multimodality.group/), [Xiaoyu Du](https://bio.duxy.cc/), Ruizhuo Gao, Feng Xu.
> <br>
> **MEP-3M: A Large-scale Multi-modal E-Commerce Products Dataset**
> <br>
> IJCAI-21 Workshop on Long-Tailed Distribution Learning, 2021. [[paper](https://www.researchgate.net/publication/353946545_MEP-3M_A_Large-scale_Multi-modal_E-Commerce_Products_Dataset)] (Best Dataset Paper Award)
> <br>
> Pattern Recognition, Volume 140, Page 109519 (2023). [[doi](https://doi.org/10.1016/j.patcog.2023.109519)]

![graphical abstract](assets/mep-3m.jpg)

The MEP-3M consists of over **3 million** products and **599** fine-grained product categories. Each product is represented with an image-text pair and annotated with hierarchical labels. The data is collected from several Chinese online shopping websites. The text is in simplified Chinese. Key features of MEP-3M include:

- **Large-scale.** MEP-3M dataset consists of over 3 million product samples in total. Each sample consists of an image-text pair, resulting in 3,012,959 images and 156,069,329 characters. The entire dataset takes approximately 76GB of storage.  
- **Hierarchical-categorized.** Three levels of the label are given. There are 14 classes (first level), 599 sub-classes (second level), and 13 sub-classes have further sub-sub-classes (third level).
- **Multi-modal.** Each product has both image and Chinese label and title. 
- **Fine-grained.** There are a total of 599 sub-classes, and many of them are fine-grained (e.g., different types of fruit, meat, shoes, clothes, etc.).
- **Long-tailed.** MEP-3M is highly imbalanced. Some sub-classes in the dataset have more than 90k samples, while some classes have around 30 samples. 

## Download the Dataset ğŸ“‚

The dataset consists of three parts: images, text annotations, and category metadata.

- **Images**: the images are stored in 599 `.rar` files (67GB in total) according to their sub-class label. The file names correspond to the sub-class ID.
    Image data is under preparation. Please email `fanliu@hhu.edu.cn` if you have any inquiries.
    <!-- The full images can be accessed through [Baidu Netdisk](https://pan.baidu.com/s/1LrH9a67yi_-hFFVEGjTAlw?pwd=3209) (passcode: 3209) or the [Huggingface Repo](https://huggingface.co/datasets/chendelong/MEP-3M). --> 

- **Text Annotations**: the text annotations are stored in a single `annotation.json` file (1.58GB), which can be downloaded through [Baidu Netdisk](https://pan.baidu.com/s/1NncYjzZ0JL_W4-kawTGd_g?pwd=3209 ) (passcode: 3209) or the [Huggingface Repo](https://huggingface.co/datasets/chendelong/MEP-3M). We include a small sample file [`annotations-1k.json`](./annotations-1k.json) in this repo. Each sample is represented as a dictionary, for example:

    ```json
    {
        "class_id": "7",
        "class_name": "æ¯å©´/ç©å…·/ç«¥è£…",
        "sub_class_id": "1",
        "sub_class_name": "å­•å¦ˆå¥¶ç²‰",
        "subsub_class_id": "FALSE",
        "subsub_class_name": "FALSE",
        "img_path": "Images/1/4.jpg",
        "img_resolution": [
            220,
            220,
            3
        ],
        "title": "ã€é€è¯•ç”¨è£…ã€‘ä¼Šåˆ©é‡‘é¢†å† å­•å¦‡å¦ˆå¦ˆå¥¶ç²‰900gå«DHAæ­£å“æ€€å­•æœŸå­•ä¸­æœŸäº§å¦‡å¦ˆå¦ˆå¥¶ç²‰",
        "OCR": "æ–°å®¢ä¹°1é€1 180å…‹ ç›’è£…ç¥ˆå®¢é€ 6é‡‘é¢†å† uu45é¼¾ä¸“ å…ƒè¯•å–å¯é˜²ä¼ªå¯ç§¯åˆ†"
    },
    ```

- **Category Metadata**: it provides class name - class ID mapping and the hierarchical information of the dataset. It is directly include in this github repo: [dataset_info.xlsx](./dataset_info.xlsx).

    | class_id | class_name          | sub_class_idâ†‘ | sub_class_name | subsub_class_id | subsub_class_name |
    | -------- | ------------------- | ------------- | -------------- | --------------- | ----------------- |
    | 7        | æ¯å©´/ç©å…·/ç«¥è£…      | 1             | å­•å¦ˆå¥¶ç²‰       | FALSE           | FALSE             |
    | 7        | æ¯å©´/ç©å…·/ç«¥è£…      | 2             | å©´å¹¼å„¿å¥¶ç²‰     | FALSE           | FALSE             |
    | 5        | é£Ÿå“/é…’æ°´/ç”Ÿé²œ/ç‰¹äº§ | 3             | é¥®æ–™é¥®å“       | FALSE           | FALSE             |
    | ...      | ...                 | ...           | ...            | ...             | ...               |
    | 5        | é£Ÿå“/é…’æ°´/ç”Ÿé²œ/ç‰¹äº§ | 523           | æ°´æœ           | 652             | è è/å‡¤æ¢¨         |
    | 5        | é£Ÿå“/é…’æ°´/ç”Ÿé²œ/ç‰¹äº§ | 523           | æ°´æœ           | 655             | è‰è“              |
    | 5        | é£Ÿå“/é…’æ°´/ç”Ÿé²œ/ç‰¹äº§ | 523           | æ°´æœ           | 643             | è½¦å˜å­/æ¨±æ¡ƒ       |
    | ...      | ...                 | ...           | ...            | ...             | ...               |
    | 7        | æ¯å©´/ç©å…·/ç«¥è£…      | 597           | å„¿ç«¥é…é¥°       | FALSE           | FALSE             |
    | 7        | æ¯å©´/ç©å…·/ç«¥è£…      | 598           | åºŠå“           | FALSE           | FALSE             |
    | 7        | æ¯å©´/ç©å…·/ç«¥è£…      | 599           | é˜²å°¿ç”¨å“       | FALSE           | FALSE             |

## Term of UseğŸš¨

By downloading or using the Dataset, as a Licensee I/we understand, acknowledge, and hereby agree to all the terms of use. This dataset is provided "as is" and without any warranty of any kind, express or implied. The authors and their affiliated institutions are not responsible for any errors or omissions in the dataset, or for the results obtained from the use of the dataset. **The dataset is intended for academic research purposes only, and not for any commercial or other purposes.** The users of the dataset agree to acknowledge the source of the dataset and cite the relevant papers in any publications or presentations that use the dataset. The users of the dataset also agree to respect the intellectual property rights of the original data owners.


## CitationğŸˆ

If you use the MEP-3M dataset in your work, please cite it as:

```bibtex
@article{liu2023mep,
  author       = {Fan Liu and
                  Delong Chen and
                  Xiaoyu Du and
                  Ruizhuo Gao and
                  Feng Xu},
  title        = {{MEP-3M:} {A} large-scale multi-modal E-commerce product dataset},
  journal      = {Pattern Recognition},
  volume       = {140},
  pages        = {109519},
  year         = {2023},
  url          = {https://doi.org/10.1016/j.patcog.2023.109519},
  doi          = {10.1016/J.PATCOG.2023.109519},
}
```
